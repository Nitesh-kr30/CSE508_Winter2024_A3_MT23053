{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7969043,"sourceType":"datasetVersion","datasetId":4688916},{"sourceId":7969348,"sourceType":"datasetVersion","datasetId":4689122}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-08T17:05:04.703915Z","iopub.execute_input":"2024-04-08T17:05:04.704395Z","iopub.status.idle":"2024-04-08T17:05:05.937800Z","shell.execute_reply.started":"2024-04-08T17:05:04.704361Z","shell.execute_reply":"2024-04-08T17:05:05.936520Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/ir-assignment3/Electronics_5.json\n/kaggle/input/ir-metadata/meta_Electronics.json\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport json\n\ndef parse(path):\n    with open(path, 'r') as file:\n        for line in file:\n            yield json.loads(line)\n\ndef getDF(path):\n    i = 0\n    df = {}\n    for d in parse(path):\n        df[i] = d\n        i += 1\n    return pd.DataFrame.from_dict(df, orient='index')\n\ndf = getDF('/kaggle/input/ir-assignment3/Electronics_5.json')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-08T17:05:06.964451Z","iopub.execute_input":"2024-04-08T17:05:06.965195Z","iopub.status.idle":"2024-04-08T17:08:12.408644Z","shell.execute_reply.started":"2024-04-08T17:05:06.965147Z","shell.execute_reply":"2024-04-08T17:08:12.407631Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(df.head(10))","metadata":{"execution":{"iopub.status.busy":"2024-04-08T16:19:47.085403Z","iopub.execute_input":"2024-04-08T16:19:47.085790Z","iopub.status.idle":"2024-04-08T16:19:47.147381Z","shell.execute_reply.started":"2024-04-08T16:19:47.085760Z","shell.execute_reply":"2024-04-08T16:19:47.146224Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"   overall vote  verified   reviewTime      reviewerID        asin  \\\n0      5.0   67      True  09 18, 1999   AAP7PPBU72QFM  0151004714   \n1      3.0    5      True  10 23, 2013  A2E168DTVGE6SV  0151004714   \n2      5.0    4     False   09 2, 2008  A1ER5AYS3FQ9O3  0151004714   \n3      5.0   13     False   09 4, 2000  A1T17LMQABMBN5  0151004714   \n4      3.0    8      True   02 4, 2000  A3QHJ0FXK33OBE  0151004714   \n5      4.0  NaN      True   06 5, 2013  A3IYSOTP3HA77N  0380709473   \n6      5.0  NaN      True  06 27, 2016  A11SXV34PZUQ5E  0380709473   \n7      5.0  NaN      True  07 30, 2015  A2AUQM1HT2D5T8  0380709473   \n8      5.0  NaN      True  02 16, 2015  A3UD8JRWLX6SRX  0380709473   \n9      4.0  NaN     False  11 21, 2013  A3MV1KKHX51FYT  0380709473   \n\n                            style      reviewerName  \\\n0       {'Format:': ' Hardcover'}      D. C. Carrad   \n1  {'Format:': ' Kindle Edition'}               Evy   \n2       {'Format:': ' Paperback'}             Kcorn   \n3       {'Format:': ' Hardcover'}   Caf Girl Writes   \n4       {'Format:': ' Hardcover'}  W. Shane Schmidt   \n5  {'Format:': ' Kindle Edition'}          B. Marks   \n6  {'Format:': ' Kindle Edition'}            Tom C.   \n7  {'Format:': ' Kindle Edition'}               ema   \n8       {'Format:': ' Paperback'}        Michael O.   \n9       {'Format:': ' Paperback'}    Acute Observer   \n\n                                          reviewText  \\\n0  This is the best novel I have read in 2 or 3 y...   \n1  Pages and pages of introspection, in the style...   \n2  This is the kind of novel to read when you hav...   \n3  What gorgeous language! What an incredible wri...   \n4  I was taken in by reviews that compared this b...   \n5  I read this probably 50 years ago in my youth ...   \n6  I read every Perry mason book voraciously. Fin...   \n7  I love this series of Bertha and Lamb..  Great...   \n8                                        Great read!   \n9  Crows Can't Count, A.A. Fair\\n\\nMr. Harry Shar...   \n\n                                             summary  unixReviewTime image  \n0                                     A star is born       937612800   NaN  \n1                    A stream of consciousness novel      1382486400   NaN  \n2  I'm a huge fan of the author and this one did ...      1220313600   NaN  \n3          The most beautiful book I have ever read!       968025600   NaN  \n4                        A dissenting view--In part.       949622400   NaN  \n5                              Above average mystery      1370390400   NaN  \n6                                       Lam is cool!      1466985600   NaN  \n7                                         Five Stars      1438214400   NaN  \n8                                         Five Stars      1424044800   NaN  \n9                    A Fast and Far Moving Adventure      1384992000   NaN  \n","output_type":"stream"}]},{"cell_type":"code","source":"chosen_product_title = \"Headphones\"\nchosen_product = df.loc[df['vote'] == chosen_product_title]\n\n# Displaying the chosen product\nprint(chosen_product)","metadata":{"execution":{"iopub.status.busy":"2024-04-08T16:19:50.025719Z","iopub.execute_input":"2024-04-08T16:19:50.026727Z","iopub.status.idle":"2024-04-08T16:19:50.537009Z","shell.execute_reply.started":"2024-04-08T16:19:50.026688Z","shell.execute_reply":"2024-04-08T16:19:50.535634Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Empty DataFrame\nColumns: [overall, vote, verified, reviewTime, reviewerID, asin, style, reviewerName, reviewText, summary, unixReviewTime, image]\nIndex: []\n","output_type":"stream"}]},{"cell_type":"code","source":"num_rows = df.shape[0]\nprint(\"Number of rows in the DataFrame:\", num_rows)","metadata":{"execution":{"iopub.status.busy":"2024-04-08T16:19:52.500528Z","iopub.execute_input":"2024-04-08T16:19:52.501240Z","iopub.status.idle":"2024-04-08T16:19:52.507017Z","shell.execute_reply.started":"2024-04-08T16:19:52.501208Z","shell.execute_reply":"2024-04-08T16:19:52.505845Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Number of rows in the DataFrame: 6739590\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Reading Metadata","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport json\nfrom bs4 import BeautifulSoup","metadata":{"execution":{"iopub.status.busy":"2024-04-08T16:37:56.349342Z","iopub.execute_input":"2024-04-08T16:37:56.349787Z","iopub.status.idle":"2024-04-08T16:37:56.355931Z","shell.execute_reply.started":"2024-04-08T16:37:56.349742Z","shell.execute_reply":"2024-04-08T16:37:56.354516Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport json\n\ndef parse(path):\n    with open(path, 'r') as file:\n        for line in file:\n            yield json.loads(line)\n\ndef getDF(path):\n    i = 0\n    df = {}\n    for d in parse(path):\n        df[i] = d\n        i += 1\n    return pd.DataFrame.from_dict(df, orient='index')\n\ndf1 = getDF('/kaggle/input/ir-metadata/meta_Electronics.json')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-08T16:20:04.175503Z","iopub.execute_input":"2024-04-08T16:20:04.176018Z","iopub.status.idle":"2024-04-08T16:23:38.118321Z","shell.execute_reply.started":"2024-04-08T16:20:04.175957Z","shell.execute_reply":"2024-04-08T16:23:38.116622Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df1.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-08T16:23:56.934293Z","iopub.execute_input":"2024-04-08T16:23:56.934652Z","iopub.status.idle":"2024-04-08T16:23:56.976648Z","shell.execute_reply.started":"2024-04-08T16:23:56.934625Z","shell.execute_reply":"2024-04-08T16:23:56.975356Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                            category tech1  \\\n0  [Electronics, Camera &amp; Photo, Video Survei...         \n1                  [Electronics, Camera &amp; Photo]         \n2  [Electronics, eBook Readers &amp; Accessories,...         \n3  [Electronics, eBook Readers & Accessories, eBo...         \n4  [Electronics, eBook Readers & Accessories, eBo...         \n\n                                         description fit  \\\n0  [The following camera brands and models have b...       \n1  [This second edition of the Handbook of Astron...       \n2  [A zesty tale. (Publishers Weekly)<br /><br />...       \n3                                                 []       \n4  [&#8220;sex.lies.murder.fame. is brillllli&#82...       \n\n                                               title  \\\n0  Genuine Geovision 1 Channel 3rd Party NVR IP S...   \n1  Books \"Handbook of Astronomical Image Processi...   \n2                                     One Hot Summer   \n3  Hurray for Hattie Rabbit: Story and pictures (...   \n4                     sex.lies.murder.fame.: A Novel   \n\n                               also_buy tech2  \\\n0                                    []         \n1                          [0999470906]         \n2              [0425167798, 039914157X]         \n3  [0060219521, 0060219580, 0060219394]         \n4                                    []         \n\n                                          brand  \\\n0                                     GeoVision   \n1                                  33 Books Co.   \n2  Visit Amazon's Carolina Garcia Aguilera Page   \n3           Visit Amazon's Dick Gackenbach Page   \n4              Visit Amazon's Lolita Files Page   \n\n                                             feature  \\\n0  [Genuine Geovision 1 Channel NVR IP Software, ...   \n1  [Detailed chapters cover these fundamental top...   \n2                                                 []   \n3                                                 []   \n4                                                 []   \n\n                                                rank  \\\n0  [>#3,092 in Tools &amp; Home Improvement &gt; ...   \n1  [>#55,933 in Camera &amp; Photo (See Top 100 i...   \n2                               3,105,177 in Books (   \n3                               2,024,298 in Books (   \n4                               3,778,828 in Books (   \n\n                              also_view            main_cat similar_item  \\\n0                                    []  Camera &amp; Photo                \n1  [0943396670, 1138055360, 0999470906]  Camera &amp; Photo                \n2                                    []               Books                \n3  [0060219521, 0060219475, 0060219394]               Books                \n4                                    []               Books                \n\n               date                                              price  \\\n0  January 28, 2014                                             $65.00   \n1     June 17, 2003                                                      \n2                                                               $11.49   \n3                    .a-section.a-spacing-mini{margin-bottom:6px!im...   \n4                                                               $13.95   \n\n         asin                                           imageURL  \\\n0  0011300000  [https://images-na.ssl-images-amazon.com/image...   \n1  0043396828  [https://images-na.ssl-images-amazon.com/image...   \n2  0060009810                                                 []   \n3  0060219602                                                 []   \n4  0060786817                                                 []   \n\n                                     imageURLHighRes details  \n0  [https://images-na.ssl-images-amazon.com/image...     NaN  \n1  [https://images-na.ssl-images-amazon.com/image...     NaN  \n2                                                 []     NaN  \n3                                                 []     NaN  \n4                                                 []     NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n      <th>tech1</th>\n      <th>description</th>\n      <th>fit</th>\n      <th>title</th>\n      <th>also_buy</th>\n      <th>tech2</th>\n      <th>brand</th>\n      <th>feature</th>\n      <th>rank</th>\n      <th>also_view</th>\n      <th>main_cat</th>\n      <th>similar_item</th>\n      <th>date</th>\n      <th>price</th>\n      <th>asin</th>\n      <th>imageURL</th>\n      <th>imageURLHighRes</th>\n      <th>details</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[Electronics, Camera &amp;amp; Photo, Video Survei...</td>\n      <td></td>\n      <td>[The following camera brands and models have b...</td>\n      <td></td>\n      <td>Genuine Geovision 1 Channel 3rd Party NVR IP S...</td>\n      <td>[]</td>\n      <td></td>\n      <td>GeoVision</td>\n      <td>[Genuine Geovision 1 Channel NVR IP Software, ...</td>\n      <td>[&gt;#3,092 in Tools &amp;amp; Home Improvement &amp;gt; ...</td>\n      <td>[]</td>\n      <td>Camera &amp;amp; Photo</td>\n      <td></td>\n      <td>January 28, 2014</td>\n      <td>$65.00</td>\n      <td>0011300000</td>\n      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[Electronics, Camera &amp;amp; Photo]</td>\n      <td></td>\n      <td>[This second edition of the Handbook of Astron...</td>\n      <td></td>\n      <td>Books \"Handbook of Astronomical Image Processi...</td>\n      <td>[0999470906]</td>\n      <td></td>\n      <td>33 Books Co.</td>\n      <td>[Detailed chapters cover these fundamental top...</td>\n      <td>[&gt;#55,933 in Camera &amp;amp; Photo (See Top 100 i...</td>\n      <td>[0943396670, 1138055360, 0999470906]</td>\n      <td>Camera &amp;amp; Photo</td>\n      <td></td>\n      <td>June 17, 2003</td>\n      <td></td>\n      <td>0043396828</td>\n      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[Electronics, eBook Readers &amp;amp; Accessories,...</td>\n      <td></td>\n      <td>[A zesty tale. (Publishers Weekly)&lt;br /&gt;&lt;br /&gt;...</td>\n      <td></td>\n      <td>One Hot Summer</td>\n      <td>[0425167798, 039914157X]</td>\n      <td></td>\n      <td>Visit Amazon's Carolina Garcia Aguilera Page</td>\n      <td>[]</td>\n      <td>3,105,177 in Books (</td>\n      <td>[]</td>\n      <td>Books</td>\n      <td></td>\n      <td></td>\n      <td>$11.49</td>\n      <td>0060009810</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[Electronics, eBook Readers &amp; Accessories, eBo...</td>\n      <td></td>\n      <td>[]</td>\n      <td></td>\n      <td>Hurray for Hattie Rabbit: Story and pictures (...</td>\n      <td>[0060219521, 0060219580, 0060219394]</td>\n      <td></td>\n      <td>Visit Amazon's Dick Gackenbach Page</td>\n      <td>[]</td>\n      <td>2,024,298 in Books (</td>\n      <td>[0060219521, 0060219475, 0060219394]</td>\n      <td>Books</td>\n      <td></td>\n      <td></td>\n      <td>.a-section.a-spacing-mini{margin-bottom:6px!im...</td>\n      <td>0060219602</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[Electronics, eBook Readers &amp; Accessories, eBo...</td>\n      <td></td>\n      <td>[&amp;#8220;sex.lies.murder.fame. is brillllli&amp;#82...</td>\n      <td></td>\n      <td>sex.lies.murder.fame.: A Novel</td>\n      <td>[]</td>\n      <td></td>\n      <td>Visit Amazon's Lolita Files Page</td>\n      <td>[]</td>\n      <td>3,778,828 in Books (</td>\n      <td>[]</td>\n      <td>Books</td>\n      <td></td>\n      <td></td>\n      <td>$13.95</td>\n      <td>0060786817</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df1.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-08T16:42:03.890721Z","iopub.execute_input":"2024-04-08T16:42:03.891166Z","iopub.status.idle":"2024-04-08T16:42:03.898526Z","shell.execute_reply.started":"2024-04-08T16:42:03.891110Z","shell.execute_reply":"2024-04-08T16:42:03.897358Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"(756077, 19)"},"metadata":{}}]},{"cell_type":"code","source":"df1=df1.drop_duplicates(subset=[\"asin\"])\ndf1.shape\ndf1.columns","metadata":{"execution":{"iopub.status.busy":"2024-04-08T16:42:36.258040Z","iopub.execute_input":"2024-04-08T16:42:36.258497Z","iopub.status.idle":"2024-04-08T16:42:37.341694Z","shell.execute_reply.started":"2024-04-08T16:42:36.258461Z","shell.execute_reply":"2024-04-08T16:42:37.340401Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"Index(['category', 'tech1', 'description', 'fit', 'title', 'also_buy', 'tech2',\n       'brand', 'feature', 'rank', 'also_view', 'main_cat', 'similar_item',\n       'date', 'price', 'asin', 'imageURL', 'imageURLHighRes', 'details'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2024-04-08T16:42:52.016591Z","iopub.execute_input":"2024-04-08T16:42:52.017349Z","iopub.status.idle":"2024-04-08T16:42:52.024453Z","shell.execute_reply.started":"2024-04-08T16:42:52.017315Z","shell.execute_reply":"2024-04-08T16:42:52.023223Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"Index(['overall', 'vote', 'verified', 'reviewTime', 'reviewerID', 'asin',\n       'style', 'reviewerName', 'reviewText', 'summary', 'unixReviewTime',\n       'image'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"asin_list=df1[\"asin\"]\ndf=df[df[\"asin\"].isin(asin_list)]\ndf","metadata":{"execution":{"iopub.status.busy":"2024-04-08T16:44:01.953592Z","iopub.execute_input":"2024-04-08T16:44:01.954056Z","iopub.status.idle":"2024-04-08T16:44:05.451857Z","shell.execute_reply.started":"2024-04-08T16:44:01.954017Z","shell.execute_reply":"2024-04-08T16:44:05.450503Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"         overall vote  verified   reviewTime      reviewerID        asin  \\\n0            5.0   67      True  09 18, 1999   AAP7PPBU72QFM  0151004714   \n1            3.0    5      True  10 23, 2013  A2E168DTVGE6SV  0151004714   \n2            5.0    4     False   09 2, 2008  A1ER5AYS3FQ9O3  0151004714   \n3            5.0   13     False   09 4, 2000  A1T17LMQABMBN5  0151004714   \n4            3.0    8      True   02 4, 2000  A3QHJ0FXK33OBE  0151004714   \n...          ...  ...       ...          ...             ...         ...   \n6739585      4.0  NaN      True  03 21, 2017  A33MAQA919J2V8  B01HJH40WU   \n6739586      4.0  NaN      True   01 9, 2017  A1AKHSCPD1BHM4  B01HJH40WU   \n6739587      5.0    2      True   12 1, 2016  A2HUZO7MQAY5I2  B01HJH40WU   \n6739588      5.0    2      True  11 29, 2016   AJJ7VX2L91X2W  B01HJH40WU   \n6739589      5.0  NaN      True  03 31, 2017  A1FGCIRPRNZWD5  B01HJF704M   \n\n                                  style      reviewerName  \\\n0             {'Format:': ' Hardcover'}      D. C. Carrad   \n1        {'Format:': ' Kindle Edition'}               Evy   \n2             {'Format:': ' Paperback'}             Kcorn   \n3             {'Format:': ' Hardcover'}   Caf Girl Writes   \n4             {'Format:': ' Hardcover'}  W. Shane Schmidt   \n...                                 ...               ...   \n6739585                             NaN         Kurt Wurm   \n6739586                             NaN        C.L Momof3   \n6739587                             NaN    michael clontz   \n6739588                             NaN             Faith   \n6739589                             NaN            Brando   \n\n                                                reviewText  \\\n0        This is the best novel I have read in 2 or 3 y...   \n1        Pages and pages of introspection, in the style...   \n2        This is the kind of novel to read when you hav...   \n3        What gorgeous language! What an incredible wri...   \n4        I was taken in by reviews that compared this b...   \n...                                                    ...   \n6739585  These seem like quality USB cables, time will ...   \n6739586  Works great, love the longer cord. As with any...   \n6739587  Ok here is an odd thing that happened to me, I...   \n6739588                                        Works well.   \n6739589  I have it plugged into a usb extension on my g...   \n\n                                                   summary  unixReviewTime  \\\n0                                           A star is born       937612800   \n1                          A stream of consciousness novel      1382486400   \n2        I'm a huge fan of the author and this one did ...      1220313600   \n3                The most beautiful book I have ever read!       968025600   \n4                              A dissenting view--In part.       949622400   \n...                                                    ...             ...   \n6739585                                         Four Stars      1490054400   \n6739586                                     Nice long cord      1483920000   \n6739587     Not the correct product as linked in the sale.      1480550400   \n6739588                                         Five Stars      1480377600   \n6739589                                Works well enough..      1490918400   \n\n        image  \n0         NaN  \n1         NaN  \n2         NaN  \n3         NaN  \n4         NaN  \n...       ...  \n6739585   NaN  \n6739586   NaN  \n6739587   NaN  \n6739588   NaN  \n6739589   NaN  \n\n[6732848 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>overall</th>\n      <th>vote</th>\n      <th>verified</th>\n      <th>reviewTime</th>\n      <th>reviewerID</th>\n      <th>asin</th>\n      <th>style</th>\n      <th>reviewerName</th>\n      <th>reviewText</th>\n      <th>summary</th>\n      <th>unixReviewTime</th>\n      <th>image</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.0</td>\n      <td>67</td>\n      <td>True</td>\n      <td>09 18, 1999</td>\n      <td>AAP7PPBU72QFM</td>\n      <td>0151004714</td>\n      <td>{'Format:': ' Hardcover'}</td>\n      <td>D. C. Carrad</td>\n      <td>This is the best novel I have read in 2 or 3 y...</td>\n      <td>A star is born</td>\n      <td>937612800</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.0</td>\n      <td>5</td>\n      <td>True</td>\n      <td>10 23, 2013</td>\n      <td>A2E168DTVGE6SV</td>\n      <td>0151004714</td>\n      <td>{'Format:': ' Kindle Edition'}</td>\n      <td>Evy</td>\n      <td>Pages and pages of introspection, in the style...</td>\n      <td>A stream of consciousness novel</td>\n      <td>1382486400</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5.0</td>\n      <td>4</td>\n      <td>False</td>\n      <td>09 2, 2008</td>\n      <td>A1ER5AYS3FQ9O3</td>\n      <td>0151004714</td>\n      <td>{'Format:': ' Paperback'}</td>\n      <td>Kcorn</td>\n      <td>This is the kind of novel to read when you hav...</td>\n      <td>I'm a huge fan of the author and this one did ...</td>\n      <td>1220313600</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5.0</td>\n      <td>13</td>\n      <td>False</td>\n      <td>09 4, 2000</td>\n      <td>A1T17LMQABMBN5</td>\n      <td>0151004714</td>\n      <td>{'Format:': ' Hardcover'}</td>\n      <td>Caf Girl Writes</td>\n      <td>What gorgeous language! What an incredible wri...</td>\n      <td>The most beautiful book I have ever read!</td>\n      <td>968025600</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.0</td>\n      <td>8</td>\n      <td>True</td>\n      <td>02 4, 2000</td>\n      <td>A3QHJ0FXK33OBE</td>\n      <td>0151004714</td>\n      <td>{'Format:': ' Hardcover'}</td>\n      <td>W. Shane Schmidt</td>\n      <td>I was taken in by reviews that compared this b...</td>\n      <td>A dissenting view--In part.</td>\n      <td>949622400</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6739585</th>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>03 21, 2017</td>\n      <td>A33MAQA919J2V8</td>\n      <td>B01HJH40WU</td>\n      <td>NaN</td>\n      <td>Kurt Wurm</td>\n      <td>These seem like quality USB cables, time will ...</td>\n      <td>Four Stars</td>\n      <td>1490054400</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6739586</th>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>01 9, 2017</td>\n      <td>A1AKHSCPD1BHM4</td>\n      <td>B01HJH40WU</td>\n      <td>NaN</td>\n      <td>C.L Momof3</td>\n      <td>Works great, love the longer cord. As with any...</td>\n      <td>Nice long cord</td>\n      <td>1483920000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6739587</th>\n      <td>5.0</td>\n      <td>2</td>\n      <td>True</td>\n      <td>12 1, 2016</td>\n      <td>A2HUZO7MQAY5I2</td>\n      <td>B01HJH40WU</td>\n      <td>NaN</td>\n      <td>michael clontz</td>\n      <td>Ok here is an odd thing that happened to me, I...</td>\n      <td>Not the correct product as linked in the sale.</td>\n      <td>1480550400</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6739588</th>\n      <td>5.0</td>\n      <td>2</td>\n      <td>True</td>\n      <td>11 29, 2016</td>\n      <td>AJJ7VX2L91X2W</td>\n      <td>B01HJH40WU</td>\n      <td>NaN</td>\n      <td>Faith</td>\n      <td>Works well.</td>\n      <td>Five Stars</td>\n      <td>1480377600</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6739589</th>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>03 31, 2017</td>\n      <td>A1FGCIRPRNZWD5</td>\n      <td>B01HJF704M</td>\n      <td>NaN</td>\n      <td>Brando</td>\n      <td>I have it plugged into a usb extension on my g...</td>\n      <td>Works well enough..</td>\n      <td>1490918400</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>6732848 rows × 12 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Create one-hot encoding for each rating value\nrating_columns = pd.get_dummies(df['overall'], prefix='Rating')\n\n# Concatenate one-hot encoding with review_df\nreview_df_with_ratings = pd.concat([df, rating_columns], axis=1)\n\nreview_df_with_ratings\n","metadata":{"execution":{"iopub.status.busy":"2024-04-08T16:54:06.019769Z","iopub.execute_input":"2024-04-08T16:54:06.020237Z","iopub.status.idle":"2024-04-08T16:54:08.096372Z","shell.execute_reply.started":"2024-04-08T16:54:06.020201Z","shell.execute_reply":"2024-04-08T16:54:08.095201Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"         overall vote  verified   reviewTime      reviewerID        asin  \\\n0            5.0   67      True  09 18, 1999   AAP7PPBU72QFM  0151004714   \n1            3.0    5      True  10 23, 2013  A2E168DTVGE6SV  0151004714   \n2            5.0    4     False   09 2, 2008  A1ER5AYS3FQ9O3  0151004714   \n3            5.0   13     False   09 4, 2000  A1T17LMQABMBN5  0151004714   \n4            3.0    8      True   02 4, 2000  A3QHJ0FXK33OBE  0151004714   \n...          ...  ...       ...          ...             ...         ...   \n6739585      4.0  NaN      True  03 21, 2017  A33MAQA919J2V8  B01HJH40WU   \n6739586      4.0  NaN      True   01 9, 2017  A1AKHSCPD1BHM4  B01HJH40WU   \n6739587      5.0    2      True   12 1, 2016  A2HUZO7MQAY5I2  B01HJH40WU   \n6739588      5.0    2      True  11 29, 2016   AJJ7VX2L91X2W  B01HJH40WU   \n6739589      5.0  NaN      True  03 31, 2017  A1FGCIRPRNZWD5  B01HJF704M   \n\n                                  style      reviewerName  \\\n0             {'Format:': ' Hardcover'}      D. C. Carrad   \n1        {'Format:': ' Kindle Edition'}               Evy   \n2             {'Format:': ' Paperback'}             Kcorn   \n3             {'Format:': ' Hardcover'}   Caf Girl Writes   \n4             {'Format:': ' Hardcover'}  W. Shane Schmidt   \n...                                 ...               ...   \n6739585                             NaN         Kurt Wurm   \n6739586                             NaN        C.L Momof3   \n6739587                             NaN    michael clontz   \n6739588                             NaN             Faith   \n6739589                             NaN            Brando   \n\n                                                reviewText  \\\n0        This is the best novel I have read in 2 or 3 y...   \n1        Pages and pages of introspection, in the style...   \n2        This is the kind of novel to read when you hav...   \n3        What gorgeous language! What an incredible wri...   \n4        I was taken in by reviews that compared this b...   \n...                                                    ...   \n6739585  These seem like quality USB cables, time will ...   \n6739586  Works great, love the longer cord. As with any...   \n6739587  Ok here is an odd thing that happened to me, I...   \n6739588                                        Works well.   \n6739589  I have it plugged into a usb extension on my g...   \n\n                                                   summary  unixReviewTime  \\\n0                                           A star is born       937612800   \n1                          A stream of consciousness novel      1382486400   \n2        I'm a huge fan of the author and this one did ...      1220313600   \n3                The most beautiful book I have ever read!       968025600   \n4                              A dissenting view--In part.       949622400   \n...                                                    ...             ...   \n6739585                                         Four Stars      1490054400   \n6739586                                     Nice long cord      1483920000   \n6739587     Not the correct product as linked in the sale.      1480550400   \n6739588                                         Five Stars      1480377600   \n6739589                                Works well enough..      1490918400   \n\n        image  Rating_1.0  Rating_2.0  Rating_3.0  Rating_4.0  Rating_5.0  \n0         NaN       False       False       False       False        True  \n1         NaN       False       False        True       False       False  \n2         NaN       False       False       False       False        True  \n3         NaN       False       False       False       False        True  \n4         NaN       False       False        True       False       False  \n...       ...         ...         ...         ...         ...         ...  \n6739585   NaN       False       False       False        True       False  \n6739586   NaN       False       False       False        True       False  \n6739587   NaN       False       False       False       False        True  \n6739588   NaN       False       False       False       False        True  \n6739589   NaN       False       False       False       False        True  \n\n[6732848 rows x 17 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>overall</th>\n      <th>vote</th>\n      <th>verified</th>\n      <th>reviewTime</th>\n      <th>reviewerID</th>\n      <th>asin</th>\n      <th>style</th>\n      <th>reviewerName</th>\n      <th>reviewText</th>\n      <th>summary</th>\n      <th>unixReviewTime</th>\n      <th>image</th>\n      <th>Rating_1.0</th>\n      <th>Rating_2.0</th>\n      <th>Rating_3.0</th>\n      <th>Rating_4.0</th>\n      <th>Rating_5.0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.0</td>\n      <td>67</td>\n      <td>True</td>\n      <td>09 18, 1999</td>\n      <td>AAP7PPBU72QFM</td>\n      <td>0151004714</td>\n      <td>{'Format:': ' Hardcover'}</td>\n      <td>D. C. Carrad</td>\n      <td>This is the best novel I have read in 2 or 3 y...</td>\n      <td>A star is born</td>\n      <td>937612800</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.0</td>\n      <td>5</td>\n      <td>True</td>\n      <td>10 23, 2013</td>\n      <td>A2E168DTVGE6SV</td>\n      <td>0151004714</td>\n      <td>{'Format:': ' Kindle Edition'}</td>\n      <td>Evy</td>\n      <td>Pages and pages of introspection, in the style...</td>\n      <td>A stream of consciousness novel</td>\n      <td>1382486400</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5.0</td>\n      <td>4</td>\n      <td>False</td>\n      <td>09 2, 2008</td>\n      <td>A1ER5AYS3FQ9O3</td>\n      <td>0151004714</td>\n      <td>{'Format:': ' Paperback'}</td>\n      <td>Kcorn</td>\n      <td>This is the kind of novel to read when you hav...</td>\n      <td>I'm a huge fan of the author and this one did ...</td>\n      <td>1220313600</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5.0</td>\n      <td>13</td>\n      <td>False</td>\n      <td>09 4, 2000</td>\n      <td>A1T17LMQABMBN5</td>\n      <td>0151004714</td>\n      <td>{'Format:': ' Hardcover'}</td>\n      <td>Caf Girl Writes</td>\n      <td>What gorgeous language! What an incredible wri...</td>\n      <td>The most beautiful book I have ever read!</td>\n      <td>968025600</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.0</td>\n      <td>8</td>\n      <td>True</td>\n      <td>02 4, 2000</td>\n      <td>A3QHJ0FXK33OBE</td>\n      <td>0151004714</td>\n      <td>{'Format:': ' Hardcover'}</td>\n      <td>W. Shane Schmidt</td>\n      <td>I was taken in by reviews that compared this b...</td>\n      <td>A dissenting view--In part.</td>\n      <td>949622400</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6739585</th>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>03 21, 2017</td>\n      <td>A33MAQA919J2V8</td>\n      <td>B01HJH40WU</td>\n      <td>NaN</td>\n      <td>Kurt Wurm</td>\n      <td>These seem like quality USB cables, time will ...</td>\n      <td>Four Stars</td>\n      <td>1490054400</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>6739586</th>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>01 9, 2017</td>\n      <td>A1AKHSCPD1BHM4</td>\n      <td>B01HJH40WU</td>\n      <td>NaN</td>\n      <td>C.L Momof3</td>\n      <td>Works great, love the longer cord. As with any...</td>\n      <td>Nice long cord</td>\n      <td>1483920000</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>6739587</th>\n      <td>5.0</td>\n      <td>2</td>\n      <td>True</td>\n      <td>12 1, 2016</td>\n      <td>A2HUZO7MQAY5I2</td>\n      <td>B01HJH40WU</td>\n      <td>NaN</td>\n      <td>michael clontz</td>\n      <td>Ok here is an odd thing that happened to me, I...</td>\n      <td>Not the correct product as linked in the sale.</td>\n      <td>1480550400</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>6739588</th>\n      <td>5.0</td>\n      <td>2</td>\n      <td>True</td>\n      <td>11 29, 2016</td>\n      <td>AJJ7VX2L91X2W</td>\n      <td>B01HJH40WU</td>\n      <td>NaN</td>\n      <td>Faith</td>\n      <td>Works well.</td>\n      <td>Five Stars</td>\n      <td>1480377600</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>6739589</th>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>03 31, 2017</td>\n      <td>A1FGCIRPRNZWD5</td>\n      <td>B01HJF704M</td>\n      <td>NaN</td>\n      <td>Brando</td>\n      <td>I have it plugged into a usb extension on my g...</td>\n      <td>Works well enough..</td>\n      <td>1490918400</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>6732848 rows × 17 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Group by 'asin' and aggregate ratings\nproduct_grouped = review_df_with_ratings.groupby('asin').agg({\n    'Rating_1.0':'sum',\n    'Rating_2.0': 'sum',\n    'Rating_3.0': 'sum',\n    'Rating_4.0': 'sum',\n    'Rating_5.0': 'sum',\n    'overall': 'count'\n})\n\n# Rename the column for overall count to 'Number of Reviews per Product'\nproduct_grouped.rename(columns={'overall': 'Number of Reviews per Product'}, inplace=True)\n\n# Calculate Average Rating Score per Product\nproduct_grouped['Average Rating Score per Product'] = (product_grouped['Rating_1.0'] + 2*product_grouped['Rating_2.0'] + 3*product_grouped['Rating_3.0'] + 4*product_grouped['Rating_4.0'] + 5*product_grouped['Rating_5.0']) / product_grouped['Number of Reviews per Product']\n\n# Calculate Number of Good Ratings per Product\nproduct_grouped['Number of Good Ratings per Product'] = product_grouped['Rating_4.0'] + product_grouped['Rating_5.0']\n\n# Calculate Number of Bad Ratings per Product\nproduct_grouped['Number of Bad Ratings per Product'] = product_grouped['Rating_1.0'] + product_grouped['Rating_2.0'] + product_grouped['Rating_3.0']\n\n# Displaying the DataFrame\nproduct_grouped","metadata":{"execution":{"iopub.status.busy":"2024-04-08T16:58:25.618061Z","iopub.execute_input":"2024-04-08T16:58:25.618486Z","iopub.status.idle":"2024-04-08T16:58:29.157913Z","shell.execute_reply.started":"2024-04-08T16:58:25.618455Z","shell.execute_reply":"2024-04-08T16:58:29.156725Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"            Rating_1.0  Rating_2.0  Rating_3.0  Rating_4.0  Rating_5.0  \\\nasin                                                                     \n0101635370           9           2           5           5          11   \n0151004714           0           0           2           0           3   \n0380709473           0           0           0           3           3   \n0446697192           0           1           2           6           2   \n0511189877           1           2           3           3          27   \n...                ...         ...         ...         ...         ...   \nB01HJDR9DQ           1           0           0           2          12   \nB01HJF704M           2           0           1           1           6   \nB01HJFFHTC           3           0           5           8          10   \nB01HJH40WU           1           0           1           3           4   \nB01HJH42KU           0           3           3           0          12   \n\n            Number of Reviews per Product  Average Rating Score per Product  \\\nasin                                                                          \n0101635370                             32                          3.218750   \n0151004714                              5                          4.200000   \n0380709473                              6                          4.500000   \n0446697192                             11                          3.818182   \n0511189877                             36                          4.472222   \n...                                   ...                               ...   \nB01HJDR9DQ                             15                          4.600000   \nB01HJF704M                             10                          3.900000   \nB01HJFFHTC                             26                          3.846154   \nB01HJH40WU                              9                          4.000000   \nB01HJH42KU                             18                          4.166667   \n\n            Number of Good Ratings per Product  \\\nasin                                             \n0101635370                                  16   \n0151004714                                   3   \n0380709473                                   6   \n0446697192                                   8   \n0511189877                                  30   \n...                                        ...   \nB01HJDR9DQ                                  14   \nB01HJF704M                                   7   \nB01HJFFHTC                                  18   \nB01HJH40WU                                   7   \nB01HJH42KU                                  12   \n\n            Number of Bad Ratings per Product  \nasin                                           \n0101635370                                 16  \n0151004714                                  2  \n0380709473                                  0  \n0446697192                                  3  \n0511189877                                  6  \n...                                       ...  \nB01HJDR9DQ                                  1  \nB01HJF704M                                  3  \nB01HJFFHTC                                  8  \nB01HJH40WU                                  2  \nB01HJH42KU                                  6  \n\n[159935 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rating_1.0</th>\n      <th>Rating_2.0</th>\n      <th>Rating_3.0</th>\n      <th>Rating_4.0</th>\n      <th>Rating_5.0</th>\n      <th>Number of Reviews per Product</th>\n      <th>Average Rating Score per Product</th>\n      <th>Number of Good Ratings per Product</th>\n      <th>Number of Bad Ratings per Product</th>\n    </tr>\n    <tr>\n      <th>asin</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0101635370</th>\n      <td>9</td>\n      <td>2</td>\n      <td>5</td>\n      <td>5</td>\n      <td>11</td>\n      <td>32</td>\n      <td>3.218750</td>\n      <td>16</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>0151004714</th>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>5</td>\n      <td>4.200000</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>0380709473</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>6</td>\n      <td>4.500000</td>\n      <td>6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0446697192</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>6</td>\n      <td>2</td>\n      <td>11</td>\n      <td>3.818182</td>\n      <td>8</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>0511189877</th>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>27</td>\n      <td>36</td>\n      <td>4.472222</td>\n      <td>30</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>B01HJDR9DQ</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>12</td>\n      <td>15</td>\n      <td>4.600000</td>\n      <td>14</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>B01HJF704M</th>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>6</td>\n      <td>10</td>\n      <td>3.900000</td>\n      <td>7</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>B01HJFFHTC</th>\n      <td>3</td>\n      <td>0</td>\n      <td>5</td>\n      <td>8</td>\n      <td>10</td>\n      <td>26</td>\n      <td>3.846154</td>\n      <td>18</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>B01HJH40WU</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>9</td>\n      <td>4.000000</td>\n      <td>7</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>B01HJH42KU</th>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>12</td>\n      <td>18</td>\n      <td>4.166667</td>\n      <td>12</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n<p>159935 rows × 9 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import spacy\nimport re\nimport unicodedata","metadata":{"execution":{"iopub.status.busy":"2024-04-08T17:02:45.689037Z","iopub.execute_input":"2024-04-08T17:02:45.689527Z","iopub.status.idle":"2024-04-08T17:02:52.521189Z","shell.execute_reply.started":"2024-04-08T17:02:45.689491Z","shell.execute_reply":"2024-04-08T17:02:52.520106Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import spacy\nimport re\nimport unicodedata   \n# Load English tokenizer, tagger, parser, NER, and word vectors\nnlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n\n# Function to remove HTML tags\ndef remove_html_tags(text):\n    if isinstance(text, str):\n        clean = re.compile('<.*?>')\n        return re.sub(clean, '', text)\n    else:\n        return text\n\n# Function to remove accented characters\ndef remove_accented_chars(text):\n    if isinstance(text, str):\n        text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n        return text\n    else:\n        return text\n\ndef remove_special_characters(text):\n    if isinstance(text, str):\n        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n        return text\n    else:\n        return text\n\n# Function for lemmatization\ndef lemmatize_text(text):\n    if isinstance(text, str):\n        doc = nlp(text)\n        lemmatized_tokens = [token.lemma_ for token in doc]\n        return ' '.join(lemmatized_tokens)\n    else:\n        return text\n\n# Function for text normalization\ndef normalize_text(text):\n    if isinstance(text, str):\n        text = text.lower()  # Convert to lowercase\n        text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespaces\n        return text\n    else:\n        return str(text)\n\n# Apply preprocessing functions to reviewText column\ndf['reviewText'] = df['reviewText'].apply(remove_html_tags)\ndf['reviewText'] = df['reviewText'].apply(remove_accented_chars)\n# review_df['reviewText'] = review_df['reviewText'].apply(lambda x: expand_acronyms(x, acronym_expansion))\ndf['reviewText'] = df['reviewText'].apply(remove_special_characters)\ndf['reviewText'] = df['reviewText'].apply(lemmatize_text)\ndf['reviewText'] = df['reviewText'].apply(normalize_text)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-08T17:09:02.224410Z","iopub.execute_input":"2024-04-08T17:09:02.225252Z","iopub.status.idle":"2024-04-08T17:33:26.522695Z","shell.execute_reply.started":"2024-04-08T17:09:02.225198Z","shell.execute_reply":"2024-04-08T17:33:26.519882Z"},"trusted":true},"execution_count":5,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 53\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# review_df['reviewText'] = review_df['reviewText'].apply(lambda x: expand_acronyms(x, acronym_expansion))\u001b[39;00m\n\u001b[1;32m     52\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreviewText\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreviewText\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(remove_special_characters)\n\u001b[0;32m---> 53\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreviewText\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreviewText\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlemmatize_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreviewText\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreviewText\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(normalize_text)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:4915\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4780\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4781\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4782\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4787\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4788\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4790\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4791\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4906\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4907\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4908\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4909\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4913\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4915\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n","File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n","Cell \u001b[0;32mIn[5], line 33\u001b[0m, in \u001b[0;36mlemmatize_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlemmatize_text\u001b[39m(text):\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 33\u001b[0m         doc \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m         lemmatized_tokens \u001b[38;5;241m=\u001b[39m [token\u001b[38;5;241m.\u001b[39mlemma_ \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc]\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(lemmatized_tokens)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/spacy/language.py:1049\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     error_handler \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mget_error_handler()\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1049\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mproc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcomponent_cfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/spacy/pipeline/trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/spacy/pipeline/tok2vec.py:126\u001b[0m, in \u001b[0;36mTok2Vec.predict\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m    124\u001b[0m     width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnO\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39malloc((\u001b[38;5;241m0\u001b[39m, width)) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[0;32m--> 126\u001b[0m tokvecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokvecs\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/thinc/model.py:334\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OutT:\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/thinc/layers/with_array.py:36\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, Xseq, is_train)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m     33\u001b[0m     model: Model[SeqT, SeqT], Xseq: SeqT, is_train: \u001b[38;5;28mbool\u001b[39m\n\u001b[1;32m     34\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[SeqT, Callable]:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Xseq, Ragged):\n\u001b[0;32m---> 36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], \u001b[43m_ragged_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Xseq, Padded):\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _padded_forward(model, Xseq, is_train))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/thinc/layers/with_array.py:91\u001b[0m, in \u001b[0;36m_ragged_forward\u001b[0;34m(model, Xr, is_train)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ragged_forward\u001b[39m(\n\u001b[1;32m     88\u001b[0m     model: Model[SeqT, SeqT], Xr: Ragged, is_train: \u001b[38;5;28mbool\u001b[39m\n\u001b[1;32m     89\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Ragged, Callable]:\n\u001b[1;32m     90\u001b[0m     layer: Model[ArrayXd, ArrayXd] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 91\u001b[0m     Y, get_dX \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataXd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackprop\u001b[39m(dYr: Ragged) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Ragged:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Ragged(get_dX(dYr\u001b[38;5;241m.\u001b[39mdataXd), dYr\u001b[38;5;241m.\u001b[39mlengths)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/thinc/layers/maxout.py:52\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     50\u001b[0m W \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m W \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mreshape2f(W, nO \u001b[38;5;241m*\u001b[39m nP, nI)\n\u001b[0;32m---> 52\u001b[0m Y \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgemm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m Y \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mreshape1f(b, nO \u001b[38;5;241m*\u001b[39m nP)\n\u001b[1;32m     54\u001b[0m Z \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mreshape3f(Y, Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], nO, nP)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"headphones_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-08T16:24:14.950312Z","iopub.execute_input":"2024-04-08T16:24:14.950801Z","iopub.status.idle":"2024-04-08T16:24:14.992265Z","shell.execute_reply.started":"2024-04-08T16:24:14.950771Z","shell.execute_reply":"2024-04-08T16:24:14.991421Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                         category tech1  \\\n8    [Electronics, Headphones, Earbud Headphones]         \n47                      [Electronics, Headphones]         \n70   [Electronics, Headphones, Earbud Headphones]         \n126                     [Electronics, Headphones]         \n130  [Electronics, Headphones, Earbud Headphones]         \n\n                                           description fit  \\\n8    [, <b>True High Definition Sound:</b><br>With ...       \n47   [Use these high quality headphones for interne...       \n70         [Barnes and noble official nook earphones.]       \n126  [The first ever fully researched history of To...       \n130  [, <b>True High Definition Sound:</b><br />Wit...       \n\n                                                 title also_buy tech2  \\\n8    Wireless Bluetooth Headphones Earbuds with Mic...       []         \n47   Polaroid Pbm2200 PC / Gaming Stereo Headphones...       []         \n70                 Official Nook Audio Ie250 Earphones       []         \n126  In Search of Tom Bowen and the Therapy He Insp...       []         \n130  The Mutineer: Rants, Ravings, and Missives fro...       []         \n\n               brand                                            feature  \\\n8    Enter The Arena  [Superb Sound Quality: Plays crystal clear aud...   \n47          Polaroid  [Ideal for PC Internet chatting, PC / Console ...   \n70              Nook                                                 []   \n126      Fitquipment                    [Shipping from Nevada City, CA]   \n130  Enter The Arena  [Superb Sound Quality: Plays crystal clear aud...   \n\n                                                  rank also_view  \\\n8    [>#950 in Cell Phones & Accessories (See Top 1...        []   \n47   [>#3,548,269 in Cell Phones &amp; Accessories ...        []   \n70   [>#4,167,961 in Cell Phones &amp; Accessories ...        []   \n126  [>#1,434,297 in Cell Phones &amp; Accessories ...        []   \n130  [>#5,809,755 in Cell Phones &amp; Accessories ...        []   \n\n                          main_cat similar_item                date  price  \\\n8             Home Audio & Theater                 October 23, 2017  $7.99   \n47                 All Electronics                December 13, 2012          \n70        Home Audio &amp; Theater               September 18, 2013          \n126  Cell Phones &amp; Accessories                                           \n130       Home Audio &amp; Theater                 January 12, 2007          \n\n           asin                                           imageURL  \\\n8    0132492776  [https://images-na.ssl-images-amazon.com/image...   \n47   0558835155  [https://images-na.ssl-images-amazon.com/image...   \n70   0594478162  [https://images-na.ssl-images-amazon.com/image...   \n126  0646531158  [https://images-na.ssl-images-amazon.com/image...   \n130  0684873176  [https://images-na.ssl-images-amazon.com/image...   \n\n                                       imageURLHighRes details  \n8    [https://images-na.ssl-images-amazon.com/image...     NaN  \n47   [https://images-na.ssl-images-amazon.com/image...     NaN  \n70   [https://images-na.ssl-images-amazon.com/image...     NaN  \n126  [https://images-na.ssl-images-amazon.com/image...     NaN  \n130  [https://images-na.ssl-images-amazon.com/image...     NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n      <th>tech1</th>\n      <th>description</th>\n      <th>fit</th>\n      <th>title</th>\n      <th>also_buy</th>\n      <th>tech2</th>\n      <th>brand</th>\n      <th>feature</th>\n      <th>rank</th>\n      <th>also_view</th>\n      <th>main_cat</th>\n      <th>similar_item</th>\n      <th>date</th>\n      <th>price</th>\n      <th>asin</th>\n      <th>imageURL</th>\n      <th>imageURLHighRes</th>\n      <th>details</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8</th>\n      <td>[Electronics, Headphones, Earbud Headphones]</td>\n      <td></td>\n      <td>[, &lt;b&gt;True High Definition Sound:&lt;/b&gt;&lt;br&gt;With ...</td>\n      <td></td>\n      <td>Wireless Bluetooth Headphones Earbuds with Mic...</td>\n      <td>[]</td>\n      <td></td>\n      <td>Enter The Arena</td>\n      <td>[Superb Sound Quality: Plays crystal clear aud...</td>\n      <td>[&gt;#950 in Cell Phones &amp; Accessories (See Top 1...</td>\n      <td>[]</td>\n      <td>Home Audio &amp; Theater</td>\n      <td></td>\n      <td>October 23, 2017</td>\n      <td>$7.99</td>\n      <td>0132492776</td>\n      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>[Electronics, Headphones]</td>\n      <td></td>\n      <td>[Use these high quality headphones for interne...</td>\n      <td></td>\n      <td>Polaroid Pbm2200 PC / Gaming Stereo Headphones...</td>\n      <td>[]</td>\n      <td></td>\n      <td>Polaroid</td>\n      <td>[Ideal for PC Internet chatting, PC / Console ...</td>\n      <td>[&gt;#3,548,269 in Cell Phones &amp;amp; Accessories ...</td>\n      <td>[]</td>\n      <td>All Electronics</td>\n      <td></td>\n      <td>December 13, 2012</td>\n      <td></td>\n      <td>0558835155</td>\n      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>[Electronics, Headphones, Earbud Headphones]</td>\n      <td></td>\n      <td>[Barnes and noble official nook earphones.]</td>\n      <td></td>\n      <td>Official Nook Audio Ie250 Earphones</td>\n      <td>[]</td>\n      <td></td>\n      <td>Nook</td>\n      <td>[]</td>\n      <td>[&gt;#4,167,961 in Cell Phones &amp;amp; Accessories ...</td>\n      <td>[]</td>\n      <td>Home Audio &amp;amp; Theater</td>\n      <td></td>\n      <td>September 18, 2013</td>\n      <td></td>\n      <td>0594478162</td>\n      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>126</th>\n      <td>[Electronics, Headphones]</td>\n      <td></td>\n      <td>[The first ever fully researched history of To...</td>\n      <td></td>\n      <td>In Search of Tom Bowen and the Therapy He Insp...</td>\n      <td>[]</td>\n      <td></td>\n      <td>Fitquipment</td>\n      <td>[Shipping from Nevada City, CA]</td>\n      <td>[&gt;#1,434,297 in Cell Phones &amp;amp; Accessories ...</td>\n      <td>[]</td>\n      <td>Cell Phones &amp;amp; Accessories</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>0646531158</td>\n      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>130</th>\n      <td>[Electronics, Headphones, Earbud Headphones]</td>\n      <td></td>\n      <td>[, &lt;b&gt;True High Definition Sound:&lt;/b&gt;&lt;br /&gt;Wit...</td>\n      <td></td>\n      <td>The Mutineer: Rants, Ravings, and Missives fro...</td>\n      <td>[]</td>\n      <td></td>\n      <td>Enter The Arena</td>\n      <td>[Superb Sound Quality: Plays crystal clear aud...</td>\n      <td>[&gt;#5,809,755 in Cell Phones &amp;amp; Accessories ...</td>\n      <td>[]</td>\n      <td>Home Audio &amp;amp; Theater</td>\n      <td></td>\n      <td>January 12, 2007</td>\n      <td></td>\n      <td>0684873176</td>\n      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-04-08T16:38:41.102274Z","iopub.execute_input":"2024-04-08T16:38:41.103478Z","iopub.status.idle":"2024-04-08T16:38:41.111825Z","shell.execute_reply.started":"2024-04-08T16:38:41.103438Z","shell.execute_reply":"2024-04-08T16:38:41.110746Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}]},{"cell_type":"code","source":"headphones_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_rows = headphones_df.shape[0]\nprint(\"Number of rows in the DataFrame:\", num_rows)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T08:50:23.821601Z","iopub.execute_input":"2024-04-07T08:50:23.822174Z","iopub.status.idle":"2024-04-07T08:50:23.830499Z","shell.execute_reply.started":"2024-04-07T08:50:23.822137Z","shell.execute_reply":"2024-04-07T08:50:23.829064Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Number of rows in the DataFrame: 31115\n","output_type":"stream"}]},{"cell_type":"code","source":"ratings = []\n\nfor review in parse(\"/kaggle/input/ir-assignment3/Electronics_5.json\"):\n  ratings.append(review['overall'])\n\nprint(sum(ratings) / len(ratings))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T08:50:26.223443Z","iopub.execute_input":"2024-04-07T08:50:26.223928Z","iopub.status.idle":"2024-04-07T08:52:03.215100Z","shell.execute_reply.started":"2024-04-07T08:50:26.223885Z","shell.execute_reply":"2024-04-07T08:52:03.213844Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"4.26766835964799\n","output_type":"stream"}]},{"cell_type":"code","source":"# a. Number of Reviews\nnum_reviews = len(df)\n\n# b. Average Rating Score\naverage_rating = df['overall'].mean()\n\n# c. Number of Unique Products\nnum_unique_products = df['asin'].nunique()\n\n# d. Number of Good Ratings (>=3)\ngood_ratings = df[df['overall'] >= 3]['asin'].nunique()\n\n# e. Number of Bad Ratings (<3)\nbad_ratings = num_unique_products - good_ratings\n\n# f. Number of Reviews corresponding to each Rating\nrating_counts = df['overall'].value_counts().sort_index()\n\n# Print the results\nprint(\"a. Number of Reviews:\", num_reviews)\nprint(\"b. Average Rating Score:\", average_rating)\nprint(\"c. Number of Unique Products:\", num_unique_products)\nprint(\"d. Number of Good Ratings (>=3):\", good_ratings)\nprint(\"e. Number of Bad Ratings (<3):\", bad_ratings)\nprint(\"f. Number of Reviews corresponding to each Rating:\")\nprint(rating_counts)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T09:22:21.134848Z","iopub.execute_input":"2024-04-07T09:22:21.135341Z","iopub.status.idle":"2024-04-07T09:22:44.778469Z","shell.execute_reply.started":"2024-04-07T09:22:21.135309Z","shell.execute_reply":"2024-04-07T09:22:44.777136Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"a. Number of Reviews: 6739590\nb. Average Rating Score: 4.26766835964799\nc. Number of Unique Products: 160052\nd. Number of Good Ratings (>=3): 159978\ne. Number of Bad Ratings (<3): 74\nf. Number of Reviews corresponding to each Rating:\noverall\n1.0     467158\n2.0     306676\n3.0     504781\n4.0    1137393\n5.0    4323582\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation\n\n# Assuming review_df DataFrame is already loaded with review data\n\n# Separate 'Good' and 'Bad' reviews\npositive_reviews = review_df[review_df['overall'] > 3]['reviewText']\nnegative_reviews = review_df[review_df['overall'] < 3]['reviewText']\n\n# Concatenate the reviews\npositive_reviews_text = ' '.join(positive_reviews)\nnegative_reviews_text = ' '.join(negative_reviews)\n\n# Generate word clouds for 'Good' and 'Bad' reviews\npositive_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(positive_reviews_text)\nnegative_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(negative_reviews_text)\n\n# Plot the word clouds\nplt.figure(figsize=(12, 6))\n\nplt.subplot(1, 2, 1)\nplt.imshow(positive_wordcloud, interpolation='bilinear')\nplt.title('Word Cloud for Positive Reviews')\nplt.axis('off')\n\nplt.subplot(1, 2, 2)\nplt.imshow(negative_wordcloud, interpolation='bilinear')\nplt.title('Word Cloud for Negative Reviews')\nplt.axis('off')\n\nplt.show()\n\n# Additional models for text preprocessing and visualization\n\n# TF-IDF Vectorizer\ntfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\ntfidf_matrix = tfidf_vectorizer.fit_transform(review_df['reviewText'])\n\n# Count Vectorizer\ncount_vectorizer = CountVectorizer(max_features=1000, stop_words='english')\ncount_matrix = count_vectorizer.fit_transform(review_df['reviewText'])\n\n# Latent Dirichlet Allocation (LDA)\nlda = LatentDirichletAllocation(n_components=5, random_state=42)\nlda_matrix = lda.fit_transform(tfidf_matrix)\n\n# Visualize the LDA topics\ndef plot_lda_topics(lda_model, vectorizer):\n    for topic_idx, topic in enumerate(lda_model.components_):\n        print(\"Topic %d:\" % (topic_idx))\n        print(\" \".join([vectorizer.get_feature_names_out()[i] for i in topic.argsort()[:-10 - 1:-1]]))\n\n# Plot the LDA topics\nplot_lda_topics(lda, tfidf_vectorizer)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud\nfrom collections import Counter\nimport datetime\n\n# Assuming you have loaded your data into a DataFrame called df\n\n# a. Top 20 most reviewed brands\ntop_20_most_reviewed_brands = df['brand'].value_counts().head(20)\n\n# b. Top 20 least reviewed brands\ntop_20_least_reviewed_brands = df['brand'].value_counts().tail(20)\n\n# c. Most positively reviewed headphone (assuming 'overall' column represents the rating)\nmost_positively_reviewed_headphone = df[df['category'] == 'Headphones'].sort_values(by='overall', ascending=False).iloc[0]\n\n# d. Count of ratings for the product over 5 consecutive years\ndf['reviewTime'] = pd.to_datetime(df['reviewTime'])\ndf['year'] = df['reviewTime'].dt.year\ncount_of_ratings_over_years = df['year'].value_counts().sort_index()\n\n# e. Word Cloud for 'Good' and 'Bad' ratings\ngood_reviews_text = ' '.join(df[df['overall'] >= 4]['reviewText'])\nbad_reviews_text = ' '.join(df[df['overall'] <= 2]['reviewText'])\n\n# Generate word clouds\nwordcloud_good = WordCloud(width=800, height=400, background_color='white').generate(good_reviews_text)\nwordcloud_bad = WordCloud(width=800, height=400, background_color='white').generate(bad_reviews_text)\n\n# f. Pie chart for Distribution of Ratings vs. the No. of Reviews\nrating_distribution = df['overall'].value_counts()\n\n# g. Year with the maximum reviews\nyear_with_max_reviews = count_of_ratings_over_years.idxmax()\n\n# h. Year with the highest number of customers (assuming each review corresponds to a unique customer)\nyear_with_max_customers = df.drop_duplicates(subset=['reviewerID']).groupby('year').size().idxmax()\n\n# Plotting\nplt.figure(figsize=(10, 6))\n\n# Subplot for Word Clouds\nplt.subplot(2, 2, 1)\nplt.imshow(wordcloud_good, interpolation='bilinear')\nplt.title('Word Cloud for Good Reviews')\nplt.axis('off')\n\nplt.subplot(2, 2, 2)\nplt.imshow(wordcloud_bad, interpolation='bilinear')\nplt.title('Word Cloud for Bad Reviews')\nplt.axis('off')\n\n# Subplot for Rating Distribution Pie Chart\nplt.subplot(2, 2, 3)\nplt.pie(rating_distribution, labels=rating_distribution.index, autopct='%1.1f%%')\nplt.title('Distribution of Ratings')\n\n# Subplot for Count of Ratings over 5 Consecutive Years\nplt.subplot(2, 2, 4)\ncount_of_ratings_over_years.plot(kind='bar', color='skyblue')\nplt.xlabel('Year')\nplt.ylabel('Number of Ratings')\nplt.title('Count of Ratings over 5 Consecutive Years')\n\nplt.tight_layout()\nplt.show()\n\n# Print the results\nprint(\"Top 20 most reviewed brands:\")\nprint(top_20_most_reviewed_brands)\nprint(\"\\nTop 20 least reviewed brands:\")\nprint(top_20_least_reviewed_brands)\nprint(\"\\nMost positively reviewed headphone:\")\nprint(most_positively_reviewed_headphone)\nprint(\"\\nYear with maximum reviews:\", year_with_max_reviews)\nprint(\"\\nYear with highest number of customers:\", year_with_max_customers)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom gensim.models import Word2Vec\n\n# Assuming you have a DataFrame named 'overall' containing ratings\n\n# Step 1: Preprocess the text data (if necessary)\n# If your 'overall' DataFrame already contains text data in a suitable format, no preprocessing is required\n\n# Step 2: Train a Word2Vec model\n# Example training data (replace with your actual data)\ntraining_data = overall['rating_column'].apply(lambda x: x.split())  # Assuming 'rating_column' contains the text data\nword2vec_model = Word2Vec(sentences=training_data, vector_size=100, window=5, min_count=1, workers=4)  # Adjust parameters as needed\n\n# Step 3: Calculate Word2Vec features for each column\nword2vec_features = {}\nfor column in overall.columns:\n    # Assuming each column contains text data (replace 'rating_column' with the actual column name)\n    column_data = overall[column].apply(lambda x: x.split())\n    column_word2vec = column_data.apply(lambda x: [word2vec_model.wv[word] for word in x if word in word2vec_model.wv])\n    word2vec_features[column] = column_word2vec\n\n# Step 4: Create a new DataFrame to store Word2Vec features\nword2vec_df = pd.DataFrame(word2vec_features)\n\n# Now 'word2vec_df' contains Word2Vec features for each column in the 'overall' DataFrame\n\n# Additional operations\n# 1. Perform dimensionality reduction using PCA\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=50)\nword2vec_pca = pca.fit_transform(word2vec_df)\n\n# 2. Calculate cosine similarity between Word2Vec vectors\nfrom sklearn.metrics.pairwise import cosine_similarity\ncosine_sim = cosine_similarity(word2vec_df)\n\n# 3. Perform clustering using KMeans\nfrom sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=5)\ncluster_labels = kmeans.fit_predict(word2vec_df)\n\n# 4. Export the Word2Vec model\nword2vec_model.save('word2vec_model.bin')\n\n# 5. Load a saved Word2Vec model\nloaded_word2vec_model = Word2Vec.load('word2vec_model.bin')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import classification_report\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Assuming 'review_df' DataFrame contains 'reviewText' and 'Rating Class' columns\n\n# TF-IDF vectorization\ntfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Adjust max_features as needed\nX = tfidf_vectorizer.fit_transform(review_df['reviewText'])\ny = review_df['Rating Class']\n\n# Split the data into train and test sets (75:25 ratio)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n\n# Initialize and train Logistic Regression model\nlogistic_regression_model = LogisticRegression()\nlogistic_regression_model.fit(X_train, y_train)\n\n# Make predictions and evaluate Logistic Regression model\ny_pred_lr = logistic_regression_model.predict(X_test)\nclassification_rep_lr = classification_report(y_test, y_pred_lr)\nprint(\"Classification Report for Logistic Regression:\")\nprint(classification_rep_lr)\n\n# Initialize and train Support Vector Machine (SVM) model\nsvm_model = SVC()\nsvm_model.fit(X_train, y_train)\n\n# Make predictions and evaluate SVM model\ny_pred_svm = svm_model.predict(X_test)\nclassification_rep_svm = classification_report(y_test, y_pred_svm)\nprint(\"Classification Report for Support Vector Machine:\")\nprint(classification_rep_svm)\n\n# Initialize and train Random Forest Classifier model\nrandom_forest_model = RandomForestClassifier()\nrandom_forest_model.fit(X_train, y_train)\n\n# Make predictions and evaluate Random Forest Classifier model\ny_pred_rf = random_forest_model.predict(X_test)\nclassification_rep_rf = classification_report(y_test, y_pred_rf)\nprint(\"Classification Report for Random Forest Classifier:\")\nprint(classification_rep_rf)\n\n# Initialize and train Decision Tree Classifier model\ndecision_tree_model = DecisionTreeClassifier()\ndecision_tree_model.fit(X_train, y_train)\n\n# Make predictions and evaluate Decision Tree Classifier model\ny_pred_dt = decision_tree_model.predict(X_test)\nclassification_rep_dt = classification_report(y_test, y_pred_dt)\nprint(\"Classification Report for Decision Tree Classifier:\")\nprint(classification_rep_dt)\n\n# Initialize and train K-Nearest Neighbors (KNN) model\nknn_model = KNeighborsClassifier()\nknn_model.fit(X_train, y_train)\n\n# Make predictions and evaluate KNN model\ny_pred_knn = knn_model.predict(X_test)\nclassification_rep_knn = classification_report(y_test, y_pred_knn)\nprint(\"Classification Report for K-Nearest Neighbors:\")\nprint(classification_rep_knn)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}